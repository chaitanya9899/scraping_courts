{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "import re\n",
    "import time;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chrome Driver path\n",
    "path_driver = \"chromedriver\"\n",
    "\n",
    "driver = webdriver.Chrome(path_driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classes for user and bio\n",
    "class User:\n",
    "    def __init__(self, user_id, name, \n",
    "                 followers, following, total_posts, bio,\n",
    "                 bio_emails,profile_picture, privacy,\n",
    "                influencer, buisness):\n",
    "        self.user_id = user_id\n",
    "        self.name = name\n",
    "        self.followers = followers\n",
    "        self.following = following\n",
    "        self.total_posts = total_posts\n",
    "        self.bio = bio\n",
    "        self.profile_picture = profile_picture\n",
    "        self.privacy_type = privacy\n",
    "        self.influencer = influencer\n",
    "        self.buisness = buisness\n",
    "        self.bio_emails = bio_emails\n",
    "\n",
    "class Bio:\n",
    "    def __init__(self, bio_description, bio_ids, bio_links, bio_tags):\n",
    "        self.bio_description = bio_description\n",
    "        self.bio_ids = bio_ids\n",
    "        self.bio_links = bio_links\n",
    "        self.bio_tags = bio_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial structure\n",
    "base_url = \"https://www.instagram.com/\"\n",
    "\n",
    "user_id = []\n",
    "name = []\n",
    "followers = []\n",
    "following = []\n",
    "total_posts = []\n",
    "profile_picture = []\n",
    "privacy_type = []\n",
    "bio_description = []\n",
    "bio_links = []\n",
    "bio_ids = []\n",
    "bio_tags = []\n",
    "influencer = []\n",
    "buisness = []\n",
    "bio_emails = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Start time : time.struct_time(tm_year=2020, tm_mon=9, tm_mday=16, tm_hour=18, tm_min=44, tm_sec=24, tm_wday=2, tm_yday=260, tm_isdst=0)\n",
      "MEN'S FASHION & STYLE\n",
      "24675\n",
      "False\n",
      "dynamic.malay\n",
      "not valid\n",
      "kratijain1606\n",
      "not valid\n",
      "MEN FASHION / FITNESS\n",
      "164234\n",
      "False\n",
      "avni\n",
      "not valid\n",
      "mishikaa9\n",
      "not valid\n",
      "Indori Zayka®\n",
      "229137\n",
      "False\n",
      "KATY PERRY\n",
      "107164331\n",
      "False\n",
      "Miley Cyrus\n",
      "115725428\n",
      "False\n",
      "Nike\n",
      "121879716\n",
      "False\n",
      "Barbie\n",
      "122961900\n",
      "False\n",
      "Jennifer Lopez\n",
      "131545784\n",
      "False\n",
      "Taylor Swift\n",
      "140666154\n",
      "False\n",
      "ene10ta Érre 🇧🇷 👻 neymarjr\n",
      "142204958\n",
      "False\n",
      "National Geographic\n",
      "145218705\n",
      "False\n",
      "Beyoncé\n",
      "154875770\n",
      "False\n",
      "Leo Messi\n",
      "166921078\n",
      "False\n",
      "Selena Gomez\n",
      "193419872\n",
      "False\n",
      "therock\n",
      "198401588\n",
      "False\n",
      "Cristiano Ronaldo\n",
      "237994187\n",
      "False\n",
      "Local Finish time : time.struct_time(tm_year=2020, tm_mon=9, tm_mday=16, tm_hour=18, tm_min=45, tm_sec=7, tm_wday=2, tm_yday=260, tm_isdst=0)\n"
     ]
    }
   ],
   "source": [
    "#insert file {}.txt\n",
    "input_file = open(\"accounts.txt\", \"r\")\n",
    "\n",
    "webScrape(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def webScrape(input_file):\n",
    "    localtime = time.localtime(time.time())\n",
    "    print (\"Local Start time :\", localtime)\n",
    "\n",
    "    for line in input_file:\n",
    "        user = getAccountDataAsync(base_url + line)\n",
    "    \n",
    "        if user != None:\n",
    "            print(user.name)\n",
    "            print(user.followers)\n",
    "            print(user.privacy_type)\n",
    "        \n",
    "            addUser(user)\n",
    "        else:\n",
    "            print(line+\"not valid\")\n",
    "\n",
    "    generateExcelFromList()        \n",
    "\n",
    "    localtime = time.localtime(time.time())\n",
    "    print (\"Local Finish time :\", localtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateExcelFromList():\n",
    "    df = pd.DataFrame({'userid':user_id,'name':name,'followers':followers,\n",
    "                       'following':following,'totalposts':total_posts,'biodescription':bio_description,\n",
    "                       'biolinks':bio_links,'bioids':bio_ids, 'biotags':bio_tags, 'bioemails':bio_emails,\n",
    "                       'profilepicture':profile_picture,'privacytype':privacy_type,\n",
    "                      'influencer':influencer,'buisness':buisness}) \n",
    "    #Storing results to {}.csv\n",
    "    df.to_csv('result1.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccountDataAsync(path) -> User:\n",
    "    driver.get(path)\n",
    "    \n",
    "    user = getAccountDetails(driver, path)\n",
    "    \n",
    "    return user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccountDetails(driver, url) -> User:\n",
    "    content = driver.page_source\n",
    "    soup = BeautifulSoup(content)\n",
    "\n",
    "    #extract userID\n",
    "    user_id = soup.find('div', {'class':'nZSzR'}).find('h2').get_text()\n",
    "    #extract user name\n",
    "    name = soup.find('div', {'class':'-vDIg'}).find('h1').get_text()\n",
    "    \n",
    "    #extract counts of posts, followers, followings\n",
    "    total_posts, followers, followings, profile_pic_src = getHeaderDetails(soup)\n",
    "    \n",
    "    #extract bio\n",
    "    bio = extractBio(soup.find('div', {'class':'-vDIg'}))\n",
    "    \n",
    "    bio_emails = extractEmails(bio.bio_description)\n",
    "    \n",
    "    influencer = True\n",
    "    buisness = True\n",
    "    #checking user validity\n",
    "    if len(bio_emails) == 0:\n",
    "        buisness = False\n",
    "    if criteria(followers, followings) is False:\n",
    "        influencer = False            \n",
    "        \n",
    "    if influencer is False and buisness is False:\n",
    "        return None\n",
    "    \n",
    "    #if private then privacy=True\n",
    "    private = checkPrivacy(soup)\n",
    "    \n",
    "    return User(user_id, name, followers, followings, total_posts, bio, bio_emails, profile_pic_src, private, influencer, buisness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHeaderDetails(soup):\n",
    "    page_details = soup.find('section', {'class':'zwlfE'}).find_all('li')\n",
    "    \n",
    "    total_posts = convert(page_details[0].find('span').get_text())\n",
    "    followers = convert(page_details[1].find('span')['title'])\n",
    "    followings = convert(page_details[2].find('span').get_text())\n",
    "    \n",
    "    profile_pic_src = soup.find('div', {'class':'XjzKX'}).find('img')['src']\n",
    "    \n",
    "    return total_posts, followers, followings, profile_pic_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkPrivacy(soup):\n",
    "    private = True\n",
    "    if soup.find('div',{'class':'Nd_Rl _2z6nI'}) is None:\n",
    "        private = False\n",
    "        \n",
    "    return private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractBio(soup):\n",
    "    bio_links = []\n",
    "    bio_ids = []\n",
    "    bio_tags = []\n",
    "    links = soup.find_all('a')\n",
    "    for link in links:\n",
    "        if \"https\" in link['href']:\n",
    "            bio_links.append(link['href'])\n",
    "            \n",
    "    \n",
    "    bio_description = None\n",
    "    description = soup.find('span')\n",
    "    \n",
    "    if description != None:\n",
    "        bio_description = description.get_text()  \n",
    "        ids = description.find_all('a')\n",
    "        if ids != None:\n",
    "            for handle in ids:\n",
    "                if '#' in handle.get_text():\n",
    "                    bio_tags.append(handle.get_text().split('#')[1])\n",
    "                elif '@' in handle.get_text():\n",
    "                    bio_ids.append(handle.get_text().split('@')[1])\n",
    "    \n",
    "    if len(bio_links) == 0:\n",
    "        bio_links = None\n",
    "    if len(bio_ids) == 0:\n",
    "        bio_ids = None\n",
    "    if len(bio_tags) == 0:\n",
    "        bio_tags = None\n",
    "        \n",
    "    return Bio(bio_description, bio_ids, bio_links, bio_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractEmails(description):\n",
    "    if description is None:\n",
    "        return []\n",
    "    match = re.findall(r'[\\w\\.-]+@[\\w\\.-]+', description)\n",
    "    return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(number):\n",
    "    if 'k' in number:\n",
    "        return int(float(number.split('k')[0])*1000)\n",
    "    if 'm' in number:\n",
    "        return int(float(number.split('m')[0])*1000000)\n",
    "    return int(number.replace(\",\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criteria(followers, followings):\n",
    "    if followers <= 2000:\n",
    "        return False\n",
    "    \n",
    "    if float(followings)/followers > 0.1:\n",
    "        return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add user to list\n",
    "def addUser(user):\n",
    "    user_id.append(user.user_id)\n",
    "    name.append(user.name)\n",
    "    followers.append(user.followers)\n",
    "    following.append(user.following)\n",
    "    total_posts.append(user.total_posts)\n",
    "    profile_picture.append(user.profile_picture)\n",
    "    privacy_type.append(user.privacy_type)\n",
    "    bio_description.append(user.bio.bio_description)\n",
    "    bio_links.append(user.bio.bio_links)\n",
    "    bio_ids.append(user.bio.bio_ids)\n",
    "    bio_tags.append(user.bio.bio_tags)\n",
    "    influencer.append(user.influencer)\n",
    "    buisness.append(user.buisness)\n",
    "    bio_emails.append(user.bio_emails)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
